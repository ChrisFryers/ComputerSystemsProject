# https://towardsdatascience.com/integrating-pyplot-and-pysimplegui-b68be606b960

# \\  -------- IMPORTS -------- //

from ast import Return
from typing import List
from unicodedata import name
import PySimpleGUI as sg
import numpy as np
import datetime as dt
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg

# cyclical imports
from statsmodels.tsa.filters.hp_filter import hpfilter

# forecasting imports
import math # Mathematical functions 
from datetime import date, timedelta, datetime # Date Functions
from pandas.plotting import register_matplotlib_converters # This function adds plotting functions for calender dates
import matplotlib.dates as mdates # Formatting dates
from sklearn.metrics import mean_absolute_error, mean_squared_error # Packages for measuring model performance / errors
from keras.models import Sequential # Deep learning library, used for neural networks
from keras.layers import LSTM, Dense, Dropout # Deep learning classes for recurrent and regular densely-connected layers
from keras.callbacks import EarlyStopping # EarlyStopping during model training
from sklearn.preprocessing import RobustScaler, MinMaxScaler # This Scaler removes the median and scales the data according to the quantile range to normalize the price data 
import seaborn as sns

# for outliers in data cleaning
from scipy import stats

# \\  -------- GET DATA -------- //

# create function importData()

def getData():

    # get data
    df = pd.read_csv(r'C:\Users\Chris\Desktop\UlsterUniversity\Final Project\PySimpleGUI\Closedf.csv', parse_dates = True, index_col = 'Date')
    df = df[['EURUSD=X', 'GBPUSD=X']]

    #remove outliers
    df = df[(np.abs(stats.zscore(df)) < 20).all(axis=1)]


    # specifying period
    end = dt.datetime.now()  # end date is now
    start = dt.datetime(2005, 1, 1)   # start date  
    df = df[start:end]
    # setting frequency
    df = df.asfreq('D') # changes frequency to daily
    #df.index # checks the frequency at bottom of printout
    
    # fill missing data using interpolate
    df = df.interpolate(method = 'linear')
    
    #returns dataframe
    return (df)

# function for correlation Matrix
def get_Corr_Matrix():
    
    # create layout and window
    layout2 = [[sg.Text('CORRERLATION MATRIX')],
              [sg.Canvas(key='figCanvas_Corr', expand_x = True, expand_y = True)]]

    _VARS['window2'] = sg.Window('CORRELATION MATRIX',
                            layout2,
                            size = (1000, 500),
                            finalize=True,
                            resizable=True,
                            location=(100, 100),
                            element_justification="center",
                            background_color='black')

    # Get data, calculate correlations and sort values
    df = getData()                                                    # get dataframe
    df_corr = df.corr()                                               # calculate and create correlation df
    df_corr = df_corr.sort_values(by = 'EURUSD=X', ascending = False) # sort values by dollar index

    # add matplot figure to pysimplefigure
    _VARS['pltFig_corr'] = plt.figure(num = 4)

    plt.figure(num = 4)  # select figure to append
    plt.clf()            # clear selected figure

    # create correlation 
    corrplot = sns.heatmap(
        data = df_corr,              # using the correlation dataframe
        cmap = 'RdYlGn_r',           # green and red colours
        square=True,                 # style of heatmap
        annot = True,                # draw number correlations on squares
        fmt='.2g',                   # round up to 2 decimal points
        annot_kws = {"fontsize": 8}  # font size of the correlation numbers on the boxes
    )
    # identify figure
    plt.figure(num = 'Correlation Figure', figsize = (11, 11)) # set figure size
    plt.title('Correlation Plot')                              # figure title
    plt.figure(num = 4)                                        # select figure to append
    plt.draw()                                                 # draw selected figure

    # draw figure to canvas
    _VARS['fig_agg_corr'] = draw_figure(
        _VARS['window2']['figCanvas_Corr'].TKCanvas, _VARS['pltFig_corr'])

# function to get list of assets from dataframe
def getAssetList():
    #get list of assets from dataset
    data = getData()
    assetsList = list(data)
    return assetsList

assetsList = getAssetList()

# \\  -------- CYCLICAL ANALYSIS -------- //
# function to get cyclcial analysis data
def get_cyclical_analysis():
    
    # getting the data
    df = getData()

    #()  asset symbol selected from list
    asset = df[assetSelected]

    asset_cycle,asset_trend = hpfilter(asset, lamb=1600*30**4)

    return asset_cycle

# function to produce forecast prediction
def get_forecast_analysis():

    # getting the data
    df = getData()

    # \\  -------- CREATING EMPTY DATAFRAME FOR PREDICTIONS -------- //

    # creating the date range
    forecast_start = dt.datetime.now()  # end date is now
    #print(forecast_start)
    forecast_end = dt.datetime.now() + timedelta(days = 29)  # starting day + forecast days - 1. 
    #print(forecast_end)
    # create date range
    dateRange = pd.date_range(start = forecast_start, end = forecast_end, freq = 'D')
    # creating empty dataframe
    df_forecast = pd.DataFrame(index = dateRange)





    # \\  -------- START LOOP TO ITER THROUGH DATAFRMAE COLUMNS -------- //


    ## start to loop around dataframe for every column
    for column_name in df:

        #column_name = name of column

        # Indexing Batches
        df_train = df.sort_values(by=['Date']).copy()

        # Save a copy of the dates index, before we need to reset it to numbers
        date_index = df_train.index

        # We reset the index, so we can convert the date-index to a number-index
        df_train = df_train.reset_index(drop=True).copy()






        # preparing the data w/ feature engineering

        def prepare_data(df):

            # List of considered Features - change to list of headings in df (df.index())
            # using all columns in df

            # Create the dataset with features and filter the data to the list of FEATURES
            df_filter = df # using all columns in df
    
            # Convert the data to numpy values
            np_filter_unscaled = np.array(df_filter)

            np_c_unscaled = np.array(df[column_name]).reshape(-1, 1)                            # change from df to df[column_name]
    
            return np_filter_unscaled, np_c_unscaled
    
        np_filter_unscaled, np_c_unscaled = prepare_data(df_train)
                                          
        # Creating a separate scaler that works on a single column for scaling predictions
        # Scale each feature to a range between 0 and 1
        scaler_train = MinMaxScaler()
        np_scaled = scaler_train.fit_transform(np_filter_unscaled)
    
        # Create a separate scaler for a single column
        scaler_pred = MinMaxScaler()
        np_scaled_c = scaler_pred.fit_transform(np_c_unscaled)  




        # \\  -------- SETTING SEQUENCE LENGTHS AND TEST AND TRAIN DATA -------- //

        # Set the input_sequence_length length - this is the timeframe used to make a single prediction - experiment witht his number to find optimal accuracy
        input_sequence_length = 50
        # The output sequence length is the number of steps that the neural network predicts
        output_sequence_length = 30 #

        # Prediction Index -  *** will need to change this to a variable to loop around df
        index_Close = df_train.columns.get_loc(column_name)

        # Split the training data into train and train data sets
        # As a first step, we get the number of rows to train the model on 80% of the data 
        train_data_length = math.ceil(np_scaled.shape[0] * 0.8)

        # Create the training and test data
        train_data = np_scaled[0:train_data_length, :]
        test_data = np_scaled[train_data_length - input_sequence_length:, :]


        # The RNN needs data with the format of [samples, time steps, features]
        # Here, we create N samples, input_sequence_length time steps per sample, and f features
        def partition_dataset(input_sequence_length, output_sequence_length, data):
            x, y = [], []
            data_len = data.shape[0]
            for i in range(input_sequence_length, data_len - output_sequence_length):
                x.append(data[i-input_sequence_length:i,:]) #contains input_sequence_length values 0-input_sequence_length * columns
                y.append(data[i:i + output_sequence_length, index_Close]) #contains the prediction values for validation (3rd column = Close),  for single-step prediction
    
            # Convert the x and y to numpy arrays
            x = np.array(x)
            y = np.array(y)
            return x, y

        # Generate training data and test data
        x_train, y_train = partition_dataset(input_sequence_length, output_sequence_length, train_data)
        x_test, y_test = partition_dataset(input_sequence_length, output_sequence_length, test_data)



        # \\  -------- CREATING MTHE RNN LSTM MODEL -------- //

        # prepare the neural network archiecture and train the multi-output regression model

        # Configure the neural network model
        model = Sequential()
        n_output_neurons = output_sequence_length

        # Model with n_neurons = inputshape Timestamps, each with x_train.shape[2] variables
        n_input_neurons = x_train.shape[1] * x_train.shape[2]
        model.add(LSTM(n_input_neurons, return_sequences=True, input_shape=(x_train.shape[1], x_train.shape[2]))) 
        model.add(LSTM(n_input_neurons, return_sequences=False))
        model.add(Dense(20))
        model.add(Dense(n_output_neurons))

        # Compile the model
        model.compile(optimizer='adam', loss='mse')




        # \\  -------- TRAINING THE MODEL -------- //


        # Training the model
        epochs = 1 # set to 13 for optimal
        batch_size = 150 # set to 12 as optimal
        early_stop = EarlyStopping(monitor='loss', patience=5, verbose=1)
        history = model.fit(x_train, y_train, 
                            batch_size=batch_size, 
                            epochs=epochs,
                            validation_data=(x_test, y_test)
                            )
                    
                            #callbacks=[early_stop])




        # \\  -------- TRANSFORMING (UNSCALING) THE DATA BACK -------- //

        # Get the predicted values
        y_pred_scaled = model.predict(x_test)

        # Unscale the predicted values
        y_pred = scaler_pred.inverse_transform(y_pred_scaled)
        y_test_unscaled = scaler_pred.inverse_transform(y_test).reshape(-1, output_sequence_length)
        y_test_unscaled.shape


        x_test_unscaled = scaler_pred.inverse_transform(np.array(pd.DataFrame(x_test[0])[index_Close]).reshape(-1, 1)) 
        df_test = pd.DataFrame(x_test_unscaled)



        # get the highest index from the x_test dataset
        index_max = x_test.shape[0]
        x_test_new = np_scaled[-51:-1,:].reshape(1,50,len(list(df))) # changed last digit from 2 to number of columns in dataframe

        # undo the scaling of the predictions
        y_pred_scaled = model.predict(x_test_new)
        y_pred = scaler_pred.inverse_transform(y_pred_scaled)

 
 

       # \\  -------- ADDING FORECASTS TO THE FORECAST DATAFRAME -------- //

       # transforming predictions to put in dataframe
        y_pred = np.array(y_pred)
        y_pred_l = np.ndarray.tolist(y_pred[0])


        # putting prediction in dataframe under its column name
        df_forecast[column_name] = y_pred_l

    return df_forecast


# VARS CONSTS:
_VARS = {'window': False,
         'fig_agg': False,
         'pltFig': False, 

         'figg_agg_cycle': False,
         'pltFig_cycle': False,

         'figg_agg_forecast': False,
         'pltFig_forecast': False,

         'window2': False,
         'figg_agg_corr': False,
         'pltFig_corr': False,

         }

# \\  -------- PYSIMPLEGUI THEME -------- //

# Theme for pyplot
plt.style.use('dark_background')

AppFont = 'Any 16'
sg.theme('black')

# \\  -------- ELEMENTS IN LAYOUT -------- //

layout = [[sg.Button('Correlations', font=AppFont), sg.Text(text = 'ASSET LIST', justification = 'right')],
          [sg.Canvas(key='figCanvas', expand_x = True, expand_y = True), sg.VerticalSeparator(), sg.Listbox( values = assetsList, size = (20, 2), enable_events = True, key = '-LISTBOX_CLICK-')],
          [sg.HorizontalSeparator()],
          [sg.Canvas(key='figCanvas_Forecast'), sg.Canvas(key='figCanvas_Cycle'), sg.VerticalSeparator(),sg.Button('Exit', font=AppFont)]]
          
# \\  -------- APPLICATION WINDOW  -------- //

_VARS['window'] = sg.Window('TickerWatch',
                            layout,
                            size = (1000, 500),
                            finalize=True,
                            resizable=True,
                            location=(100, 100),
                            element_justification="center",
                            background_color='black')

# \\  -------- PYSIMPLEGUI -------- //

# \\  -------- PYPLOTS -------- //

def draw_figure(canvas, figure):
    figure_canvas_agg = FigureCanvasTkAgg(figure, canvas)
    figure_canvas_agg.draw()
    figure_canvas_agg.get_tk_widget().pack(side='top', fill='both', expand=5)
    return figure_canvas_agg

# \\  -------- MAIN -------- //

def drawMainChart():
    _VARS['pltFig'] = plt.figure(num = 1)
    data = getData()
    plt.plot(data['EURUSD=X'])
    plt.title('EURUSD=X')
    _VARS['fig_agg'] = draw_figure(
        _VARS['window']['figCanvas'].TKCanvas, _VARS['pltFig'])

def updateMainChart():

    #getting data to display
    data = getData()

    # updating chart
    plt.figure(num = 1)           # tell the program we selecting figure 1 to update
    plt.clf()                     # clearing information on chart 
    plt.plot(data[assetSelected]) # plotting new selected data
    plt.title(assetSelected)      # adding title from seleected data
    plt.draw()                    # drawing the information on the chart


# \\  -------- CYCLICAL -------- //

# draw cycle chart function
def drawCycleChart():
    _VARS['pltFig_cycle'] = plt.figure(num = 2)
    data = getData()
    plt.plot(data['EURUSD=X'])
    plt.title('CYCLICAL TENDANCY')
    _VARS['fig_agg_cycle'] = draw_figure(
        _VARS['window']['figCanvas_Cycle'].TKCanvas, _VARS['pltFig_cycle'])

# update cycle chart function
def updateCycleChart():

    #getting data to display
    asset_cycle = get_cyclical_analysis()
    
    # updating chart
    plt.figure(num = 2)           # tell the program we selecting figure 2 to update
    plt.clf()                     # clearing information on chart
    plt.plot(asset_cycle)         # plotting new selected data
    plt.title('CYCLICAL TENDANCY') # adding title from seleected data
    plt.draw()                    # drawing the information on the chart


# \\  -------- FORECAST -------- //

# draw chart function
def drawForecastChart():
    _VARS['pltFig_forecast'] = plt.figure(num = 3)
    data = getData()
    plt.plot(data['EURUSD=X'])
    plt.title('FORECAST')
    _VARS['fig_agg_forecast'] = draw_figure(
        _VARS['window']['figCanvas_Forecast'].TKCanvas, _VARS['pltFig_forecast'])

# update chart function
def updateForecastChart(): 

    plt.figure(num = 3)                  # tell the program we selecting figure 2 to update
    plt.clf()                            # clearing the chart
    plt.plot(df_forecast[assetSelected]) # accessing the dataframe of forecasted data and picking the column of the selected object
    plt.title('FORECAST')                # adding a title
    plt.draw()                           # drawing the information on the chart


# \\  -------- PYPLOT -------- //
drawCycleChart()
drawMainChart()

df_forecast = get_forecast_analysis() # only call this once on start up as it is intensive - later improve saving file if not made already today etc
drawForecastChart()

# \\  -------- MAIN LOOP -------- //
while True:
     
    event, value = _VARS['window'].read(timeout=200)

    # if window closed or exited - break
    if event == sg.WIN_CLOSED or event == 'Exit':
        break

    # if listbox item is selected:
    if event == '-LISTBOX_CLICK-':

       # saves listbox item selected
       assetSelected = value['-LISTBOX_CLICK-']
       #calls update chart function
       updateCycleChart()

       updateMainChart()
       
       updateForecastChart()

    # if correlation button is clicked
    if event == 'Correlations':
           
        # calls correlation function
        get_Corr_Matrix()

    
    

_VARS['window'].close()
